{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class args(object):\n",
    "    pass\n",
    "    \n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "fModelName = 'model1000EnTr.pth'\n",
    "fullModelName = os.path.join('./',fModelName)\n",
    "embedding_dim = 64\n",
    "batch_size = 100\n",
    "max_epoch = 500 # 500\n",
    "learning_rate = 0.1\n",
    "learning_rate_decay = 1\n",
    "threshold = 100\n",
    "\n",
    "\n",
    "class BiLingual(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size_pri,vocab_size_sec ,embedding_dim,batch_size):\n",
    "        super(BiLingual, self).__init__()\n",
    "        self.embeddings_pri = nn.Embedding(vocab_size_pri, embedding_dim)\n",
    "        self.embeddings_sec = nn.Embedding(vocab_size_sec, embedding_dim)\n",
    "        \n",
    "    def cAdd(self,embeds):\n",
    "        btch_len = embeds.size()[0]\n",
    "        sntc_len = embeds.size()[1]\n",
    "        ret = []\n",
    "        for i in range(btch_len):\n",
    "            splt=torch.split(embeds[i],sntc_len,1)\n",
    "            tot = autograd.Variable(torch.zeros(embedding_dim),requires_grad=False).cuda()\n",
    "            for j in range(sntc_len):\n",
    "                tot = tot + embeds[i][j]\n",
    "            ret.append(tot)\n",
    "        ret=torch.stack(ret,0)\n",
    "        return ret\n",
    "       \n",
    "    def forwardPri(self, inputs):\n",
    "        embeds_pri = self.embeddings_pri(inputs)\n",
    "        out_pri = self.cAdd(embeds_pri)\n",
    "        return out_pri\n",
    "    \n",
    "    def forwardSec(self, inputs):\n",
    "        embeds_sec = self.embeddings_sec(inputs)\n",
    "        out_sec = self.cAdd(embeds_sec)\n",
    "        return out_sec\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch,threshold,lr_init,lr_decay_rate):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr_init * (lr_decay_rate ** (epoch // threshold))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(1111)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1111)\n",
    "torch.cuda.is_available(),torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file ./model1000EnTr.pth\n"
     ]
    }
   ],
   "source": [
    "print('Model file %s' % fullModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLoaded= torch.load(fullModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = pickle.load( open( \"./model.pck\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 4.2834e-02  4.1015e-01  2.7584e-01  ...  -2.1113e-01  1.1106e-01  4.8122e-01\n",
       " 5.7446e-01 -2.2783e+00 -4.8139e-02  ...  -5.8571e-01  8.9599e-01 -4.8478e-01\n",
       " 1.3280e+00 -8.1286e-03 -1.1540e+00  ...   6.8914e-01 -1.1108e+00  1.0914e+00\n",
       "                ...                   â‹±                   ...                \n",
       " 1.3663e+00 -8.7230e-01  8.5720e-01  ...   2.4645e-01  5.6051e-02 -1.7939e+00\n",
       " 4.0651e-01 -7.3624e-01  1.1642e+00  ...  -7.0021e-01 -3.9584e-01  8.1520e-01\n",
       "-6.2293e-01  1.0769e+00 -1.4651e+00  ...   9.6729e-01 -2.2503e+00 -1.4580e+00\n",
       "[torch.cuda.FloatTensor of size 3060x64 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.embeddings_pri.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3.5)",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
